- A confusion matrix is a table that describes the performance of a classification model by comparing predicted vs actual values. (table of predicted vs actual values)
    - TP (True Positive): The model predicted positive and the actual value is positive.
    - TN (True Negative): The model predicted negative and the actual value is negative.
    - FP (False Positive): The model predicted positive but the actual value is negative.
    - FN (False Negative): The model predicted negative but the actual value is positive.

- Accuracy is the ratio of correctly predicted observations to the total observations.
    - Accuracy = (TP + TN) / (TP + TN + FP + FN)

- Precision tells you how many of the predicted positives were actually correct.
    - Precision = TP / (TP + FP)

- Recall tells you how many of the actual positives your model correctly identified.
    - Recall = TP / (TP + FN)

- F1 Score is the harmonic mean of precision and recall. It balances both — especially useful when classes are imbalanced.
    - F1 Score = 2 * (Precision * Recall) / (Precision + Recall)

- [Unsupervised] Silhouette Score measures how similar a point is to its own cluster (cohesion) compared to other clusters (separation). It ranges from -1 to 1:
    - +1: Well-clustered
    -  0: On the boundary
    - -1: Misclassified

- ARI measures similarity between predicted clusters and true labels, adjusted for chance grouping. It ranges from:
    - -1 (bad) to 1 (perfect match),
    - 0 means random labeling.

- NMI measures how much information is shared between the predicted clusters and actual labels. It’s based on entropy (information theory), normalized to be between 0 and 1:

    - 1 = Perfect match
    - 0 = Completely independent (no info shared)

- FP Growth: Frequent Patternset -> Ordered Itemsets -> Conditional Pattern Base -> Conditional Pattern Tree -> Frequent Pattern Tree

- ID3: Gain(S,Attribute) = Entropy(S) - Sum(S_v/S * Entropy(S_v)) (v are all possible values for that attribute)
    - First classification based on highest Gain Attribute.
    - Then for the remaining subtrees, recursively follow the same steps (now calculate the Gain for the remaining columns, choose highest gain attribute, and repeat)

- C4.5: Here root note selected based on Maximum Gain Ratio = Gain/SplitInfo
    - Entropy_Info(T) = -Sum(PLog_2(P)) over all possible target classes.
    - Entropy_Info(T,A) = Sum(Ai/T * Entropy_Info(Ai)), v is all possible values of attribute A.
    - Gain(T,A) = Entropy_Info(T) - Entropy_Info(T,A)
    - SplitInfo(T,A) = -Sum(Ai/T * log_2(Ai/T))
    - GainRatio(T,A) = Gain(T,A)/SplitInfo(T,A)
    - Select Attribute with Highest Gain Ratio, split table, recursively follow for remaining tables (find above metrics for all attributes, select highest gain ratio, etc)

- CART: Based on Least Gini Value for attribute. Always does binary split of data while categorizing.
    - GiniIndex(T) = 1 - Sum(Pi^2), Pi are prob. of all target classes possible.
    - Compute GiniIndex for each subset of the attribute (dividing into two parts)
    - GiniIndex(T,A) = |S1|/|T| Gini(S1) + |S2|/|T| Gini(S2), S1 and S2 are the two subset splits of the attribute values of A.
    - Lowest GiniIndex(T,A) chosen, or highest (GiniIndex(T) - GiniIndex(T,A))

- PAM: select random medoids, find best cluster based on chosen metric for every point
    - compute total cost, see if it can be reduced by changing medoid one by one.